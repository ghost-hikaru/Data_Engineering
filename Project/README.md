# Projet de Data Engineering

Ce projet de Data Engineering vise à collecter et traiter des données pour alimenter un site web. Le projet comprend un scraper de données écrit en Python, ainsi que des processus de transformation et de génération de fichiers utiles pour le site web.

## Objectif du projet

L'objectif principal de ce projet est de collecter des données spécifiques à partir de sources en ligne, de les traiter et de les transformer en fichiers exploitables par le site web. Le scraper de données extrait les informations nécessaires à partir de sites web.

Une fois les données collectées, des processus de transformation sont appliqués pour nettoyer, normaliser et structurer les données de manière à les rendre prêtes à être utilisées par le site web. Les fichiers générés sont ensuite utilisés pour fournir des informations à jour et pertinentes aux utilisateurs du site.

## Fonctionnalités

Le projet de Data Engineering comprend les fonctionnalités suivantes :

1. **Scraper de données** : Un scraper de données est implémenté en utilisant Python et des bibliothèques telles que Beautiful Soup. Il est capable d'extraire des données à partir de différentes sources en ligne, en suivant des règles spécifiques définies dans le code du scraper.

2. **Traitement des données** : Une fois les données collectées, des processus de transformation sont appliqués pour nettoyer, filtrer, normaliser et structurer les données selon les besoins spécifiques du site web. Cela peut inclure le traitement des valeurs manquantes, la conversion des formats de données, la fusion de plusieurs sources de données, etc.

3. **Génération de fichiers** : Les données traitées sont utilisées pour générer des fichiers au format approprié pour le site web. Cela peut inclure des fichiers CSV. Les fichiers générés sont mis à jour régulièrement pour refléter les changements dans les sources de données.

4. **Intégration avec le site web** : Les fichiers générés sont intégrés dans le site web pour fournir des informations à jour et pertinentes aux utilisateurs. Le site web peut utiliser les données pour afficher des graphiques, des tableaux, des recommandations, des résultats de recherche, etc.

## Configuration et utilisation

Pour exécuter le scraper de données et générer les fichiers pour le site web, suivez les étapes suivantes :

1. **Installation des dépendances** : Assurez-vous d'avoir les versions appropriées des bibliothèques Python requises pour le projet. Vous pouvez utiliser un environnement virtuel pour isoler les dépendances.

2. **Exécution du scraper** : Lancez le scraper en exécutant le script Python correspondant. Le scraper collectera les données à partir des sources spécifiées, les traitera et générera les fichiers appropriés pour le site web.

3. **Intégration des fichiers générés** : Intégrez les fichiers générés dans le site web en utilisant les mécanismes appropriés.

4. **Lancement du site** : Pour lancer le site web, veillez à lancer un serveur en localhost sur votre machine.


## Auteurs

- [MATHURIN Melvin](https://github.com/ghost-hikaru)
- [VOISIN Enzo](https://github.com/Slonev0)



        
